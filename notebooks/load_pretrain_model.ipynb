{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-05T01:48:10.895617Z",
     "start_time": "2024-12-05T01:48:10.888459Z"
    }
   },
   "source": "import urllib.request",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T01:48:50.823295Z",
     "start_time": "2024-12-05T01:48:50.576890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ],
   "id": "e1f73dabe12ba546",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x7f61d27dbf50>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T01:50:45.869265Z",
     "start_time": "2024-12-05T01:50:45.864717Z"
    }
   },
   "cell_type": "code",
   "source": "from gpt_download import download_and_load_gpt2",
   "id": "f7c14d4d2f7b8214",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T01:52:54.510600Z",
     "start_time": "2024-12-05T01:51:43.028993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\",\n",
    "    models_dir=\"gpt2\"\n",
    ")"
   ],
   "id": "4b04a1b1bf5f3cac",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 16.0kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.13MiB/s]\n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 7.26kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [01:00<00:00, 8.20MiB/s] \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 1.07MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 716kiB/s] \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 748kiB/s] \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "63d9e73089a5ffa6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:12:26.860044Z",
     "start_time": "2024-12-05T23:12:26.678710Z"
    }
   },
   "cell_type": "code",
   "source": "settings",
   "id": "8d973b8ed538039e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:13:07.213658Z",
     "start_time": "2024-12-05T23:13:07.175234Z"
    }
   },
   "cell_type": "code",
   "source": "params.keys()",
   "id": "b0f90774727c98ac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:14:06.242221Z",
     "start_time": "2024-12-05T23:14:06.228945Z"
    }
   },
   "cell_type": "code",
   "source": "params['b'].shape",
   "id": "e0ce02762cbae926",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:17:26.627586Z",
     "start_time": "2024-12-05T23:17:26.617035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_configs = {\n",
    "    'gpt2-small': {'emb_dim': 768, 'n_layers':12, 'n_heads': 12}\n",
    "}"
   ],
   "id": "e5f20d491bc509cf",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:20:04.870144Z",
     "start_time": "2024-12-05T23:20:04.860113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "GPT_CONFIG_124M = {\n",
    "        \"vocab_size\": 50257,  # Vocabulary size\n",
    "        \"context_length\": 1024,  # Context length\n",
    "        \"emb_dim\": 768,  # Embedding dimension\n",
    "        \"n_heads\": 12,  # Number of attention heads\n",
    "        \"n_layers\": 12,  # Number of layers\n",
    "        \"drop_rate\": 0.1,  # Dropout rate\n",
    "        \"qkv_bias\": True  # Query-Key-Value bias\n",
    "    }"
   ],
   "id": "1896f460fb994c78",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:20:05.270051Z",
     "start_time": "2024-12-05T23:20:05.261622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs['gpt2-small'])"
   ],
   "id": "ed863d6a8bd06de9",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:25:06.573768Z",
     "start_time": "2024-12-05T23:25:06.563679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.models.gpt import GPTModel\n",
    "import torch"
   ],
   "id": "147b3c65dac9d4b2",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:21:56.441281Z",
     "start_time": "2024-12-05T23:21:52.981811Z"
    }
   },
   "cell_type": "code",
   "source": "gpt = GPTModel(NEW_CONFIG)",
   "id": "752af2ffc324cf8d",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:22:02.231693Z",
     "start_time": "2024-12-05T23:22:02.209187Z"
    }
   },
   "cell_type": "code",
   "source": "gpt.eval()",
   "id": "646155f82bf9725a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (layer_norm1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_K): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_V): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GeLU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:25:21.733775Z",
     "start_time": "2024-12-05T23:25:21.722784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f'Shape mismatch left: {left.shape},  Right: {right.shape}')\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ],
   "id": "dba5549847a4d6d8",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:47:30.970012Z",
     "start_time": "2024-12-05T23:47:30.936950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    \n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params['blocks'])):\n",
    "        \n",
    "        q_w, k_w, v_w = np.split( #3\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].multi_head_attention.W_Q.weight = assign(\n",
    "            gpt.trf_blocks[b].multi_head_attention.W_Q.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].multi_head_attention.W_K.weight = assign(\n",
    "            gpt.trf_blocks[b].multi_head_attention.W_K.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].multi_head_attention.W_V.weight = assign(\n",
    "            gpt.trf_blocks[b].multi_head_attention.W_V.weight, v_w.T)\n",
    "        \n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].multi_head_attention.W_Q.bias = assign(\n",
    "            gpt.trf_blocks[b].multi_head_attention.W_Q.bias, q_b)\n",
    "        gpt.trf_blocks[b].multi_head_attention.W_K.bias = assign(\n",
    "            gpt.trf_blocks[b].multi_head_attention.W_K.bias, k_b)\n",
    "        gpt.trf_blocks[b].multi_head_attention.W_V.bias = assign(\n",
    "            gpt.trf_blocks[b].multi_head_attention.W_V.bias, v_b)\n",
    "        gpt.trf_blocks[b].multi_head_attention.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].multi_head_attention.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        \n",
    "        gpt.trf_blocks[b].multi_head_attention.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].multi_head_attention.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "        gpt.trf_blocks[b].feed_forward.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].feed_forward.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].feed_forward.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].feed_forward.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].feed_forward.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].feed_forward.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].feed_forward.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].feed_forward.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "        gpt.trf_blocks[b].layer_norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].layer_norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].layer_norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].layer_norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].layer_norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].layer_norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].layer_norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].layer_norm2.shift,\n",
    "        params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "        \n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"]) #4"
   ],
   "id": "52c091e289733166",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:47:33.198077Z",
     "start_time": "2024-12-05T23:47:31.881365Z"
    }
   },
   "cell_type": "code",
   "source": "load_weights_into_gpt(gpt, params)",
   "id": "574008426d638d59",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:48:07.026383Z",
     "start_time": "2024-12-05T23:48:07.009931Z"
    }
   },
   "cell_type": "code",
   "source": "torch.manual_seed(77)",
   "id": "9b2f2559793dd215",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6125271c70>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:52:14.229307Z",
     "start_time": "2024-12-05T23:52:14.220605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "from src.generate import generate, text_to_token_ids, token_ids_to_text"
   ],
   "id": "5f7aaa3ad7eaf853",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:49:43.464380Z",
     "start_time": "2024-12-05T23:49:36.101864Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = tiktoken.get_encoding('gpt2')",
   "id": "7b939385c725bed5",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:58:11.320211Z",
     "start_time": "2024-12-05T23:58:07.640075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids('When i look into your eyes', tokenizer=tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG['context_length'],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")"
   ],
   "id": "23beb10bdfe3932c",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:58:11.389770Z",
     "start_time": "2024-12-05T23:58:11.376099Z"
    }
   },
   "cell_type": "code",
   "source": "token_ids_to_text(res, tokenizer=tokenizer)",
   "id": "84323fb58e168bd8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When i look into your eyes...and im thinking what your talking about but i can tell you just a few strokes below the ear of eye of ear i'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:53:55.982703Z",
     "start_time": "2024-12-05T23:53:35.726754Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(gpt.state_dict(), 'gpt2_model.pth')",
   "id": "e82706f860d584ae",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c1368136664dbde9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
